import os
# Force Hugging Face to use the writable /tmp directory on Leapcell
os.environ['HF_HOME'] = '/tmp/huggingface'

import io
import base64
from flask import Flask, request, jsonify
from flask_cors import CORS
from PIL import Image
import torch
from transformers import AutoImageProcessor, AutoModel
from supabase import create_client, Client

app = Flask(__name__)
CORS(app)

# 1. Supabase Setup (Fast, safe to run on boot)
print("üîå Connecting to Supabase...")
supabase: Client = create_client(
    os.environ.get("SUPABASE_URL"), 
    os.environ.get("SUPABASE_ANON_KEY")
)
print("‚úÖ Supabase Connected.")

# Global placeholders for the AI model
processor = None
model = None

def load_ai_model():
    """Loads the model only when requested to prevent boot timeouts"""
    global processor, model
    if model is None:
        print("üì• First request detected. Downloading/Loading DINOv2 (This takes a moment)...")
        processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')
        model = AutoModel.from_pretrained('facebook/dinov2-base')
        model.eval()
        print("‚úÖ AI Model Ready.")

@app.route('/')
def health():
    return "API is Online. Model will load on the first match request."

@app.route('/match', methods=['POST'])
def match():
    try:
        # Lazy load the model so the server boots instantly
        load_ai_model()

        data = request.get_json()
        if not data or 'image' not in data:
            print("üö® Error: No image provided in request")
            return jsonify({"error": "No image"}), 400

        print("üñºÔ∏è Processing incoming image...")
        
        # A. Decode Image
        base64_str = data['image'].split(',')[1] if ',' in data['image'] else data['image']
        image = Image.open(io.BytesIO(base64.b64decode(base64_str))).convert('RGB')
        
        # B. 70% Center Crop & Resize
        w, h = image.size
        image = image.crop((w * 0.15, h * 0.15, w * 0.85, h * 0.85))
        image.thumbnail((512, 512))
        print(f"‚úÇÔ∏è Image cropped and resized to: {image.size}")

        # C. Vectorize
        print("üß† Generating vector embedding...")
        inputs = processor(images=image, return_tensors="pt")
        with torch.no_grad():
            outputs = model(**inputs)
        
        # Get CLS token vector
        vector = outputs.last_hidden_state[:, 0, :].squeeze().tolist()
        final_vector = vector[:768]
        print("‚úÖ Vector generated successfully.")

        # D. Database Match via Supabase RPC
        print("üîç Searching Supabase for matches...")
        response = supabase.rpc('match_products_advanced', {
            'query_embedding': final_vector,
            'query_colors': ["#000000"], 
            'match_threshold': 0.35,
            'match_count': 6
        }).execute()
        
        print(f"üéâ Found {len(response.data)} matches!")
        return jsonify({"success": True, "matches": response.data})

    except Exception as e:
        print(f"üö® Error during match: {str(e)}")
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8080))
    app.run(host='0.0.0.0', port=port)